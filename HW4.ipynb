{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW: X-ray images classification\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you begin, open Mobaxterm and connect to triton with the user and password you were give with. Activate the environment `2ndPaper` and then type the command `pip install scikit-image`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will be dealing with classification of 32X32 X-ray images of the chest. The image can be classified into one of four options: lungs (l), clavicles (c), and heart (h) and background (b). Even though those labels are dependent, we will treat this task as multiclass and not as multilabel. The dataset for this assignment is located on a shared folder on triton (`/MLdata/MLcourse/X_ray/'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, MaxPool2D, Conv2D, Dropout\n",
    "from tensorflow.keras.layers import Flatten, InputLayer\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import *\n",
    "from skimage.io import imread\n",
    "\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto(gpu_options =\n",
    "                         tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "# device_count = {'GPU': 1}\n",
    ")\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(datapath):\n",
    "    # This part reads the images\n",
    "    classes = ['b','c','l','h']\n",
    "    imagelist = [fn for fn in os.listdir(datapath)]\n",
    "    N = len(imagelist)\n",
    "    num_classes = len(classes)\n",
    "    images = np.zeros((N, 32, 32, 1))\n",
    "    Y = np.zeros((N,num_classes))\n",
    "    ii=0\n",
    "    for fn in imagelist:\n",
    "\n",
    "        src = imread(os.path.join(datapath, fn),1)\n",
    "        img = resize(src,(32,32),order = 3)\n",
    "        \n",
    "        images[ii,:,:,0] = img\n",
    "        cc = -1\n",
    "        for cl in range(len(classes)):\n",
    "            if fn[-5] == classes[cl]:\n",
    "                cc = cl\n",
    "        Y[ii,cc]=1\n",
    "        ii += 1\n",
    "\n",
    "    BaseImages = images\n",
    "    BaseY = Y\n",
    "    return BaseImages, BaseY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_train_and_val(datapath):\n",
    "    # This part reads the images\n",
    "    classes = ['b','c','l','h']\n",
    "    imagelist = [fn for fn in os.listdir(datapath)]\n",
    "    N = len(imagelist)\n",
    "    num_classes = len(classes)\n",
    "    images = np.zeros((N, 32, 32, 1))\n",
    "    Y = np.zeros((N,num_classes))\n",
    "    ii=0\n",
    "    for fn in imagelist:\n",
    "\n",
    "        images[ii,:,:,0] = imread(os.path.join(datapath, fn),1)\n",
    "        cc = -1\n",
    "        for cl in range(len(classes)):\n",
    "            if fn[-5] == classes[cl]:\n",
    "                cc = cl\n",
    "        Y[ii,cc]=1\n",
    "        ii += 1\n",
    "\n",
    "    return images, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data for training and validation:\n",
    "src_data = '/MLdata/MLcourse/X_ray/'\n",
    "#src_data = 'C:\\\\Users\\\\ofeka\\\\Desktop\\\\Projects\\\\Machine Learning\\\\Homework\\\\HW4\\\\X_ray\\\\'\n",
    "train_path = src_data + 'train'\n",
    "val_path = src_data + 'validation'\n",
    "test_path = src_data + 'test'\n",
    "BaseX_train , BaseY_train = preprocess_train_and_val(train_path)\n",
    "BaseX_val , BaseY_val = preprocess_train_and_val(val_path)\n",
    "X_test, Y_test = preprocess(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6474, 32, 32, 1)\n",
      "(6629376,)\n",
      "(6474, 4)\n",
      "(1728, 32, 32, 1)\n",
      "(1728, 4)\n",
      "(175, 32, 32, 1)\n",
      "(175, 4)\n"
     ]
    }
   ],
   "source": [
    "# BLOCK FOR TESTING STUFF:\n",
    "\n",
    "print(BaseX_train.shape)\n",
    "print(BaseX_train.flatten().shape)\n",
    "print(BaseY_train.shape)\n",
    "print(BaseX_val.shape)\n",
    "print(BaseY_val.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1: Fully connected layers \n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">***Task 1:***</span> *NN with fully connected layers. \n",
    "\n",
    "Elaborate a NN with 2 hidden fully connected layers with 300, 150 neurons and 4 neurons for classification. Use ReLU activation functions for the hidden layers and He_normal for initialization. Don't forget to flatten your image before feedforward to the first dense layer. Name the model `model_relu`.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "n_filters_start = 300\n",
    "n_filters_finish = 4\n",
    "len_sub_window = 10\n",
    "dropout = 0.2\n",
    "he_normal_initializer = tf.keras.initializers.he_normal()\n",
    "model_relu = Sequential()\n",
    "model_relu.add(Flatten(input_shape = (32,32,1))) #input_shape defines the shape of the input: 32X32 is the image size, while 3 is the number of dimensions (RGB hence 3)\n",
    "model_relu.add(Dense(n_filters_start, activation='relu',kernel_initializer = he_normal_initializer)) \n",
    "model_relu.add(Dropout(dropout))\n",
    "model_relu.add(Dense(n_filters_start/2,activation='relu',kernel_initializer = he_normal_initializer))\n",
    "model_relu.add(Dropout(dropout))\n",
    "model_relu.add(Dense(n_filters_finish,activation='softmax'))\n",
    "\n",
    "\n",
    "# 2nd try model\n",
    "# model_relu_d = Sequential(name=\"model_relu\")\n",
    "# model_relu_d.add(Dense(300, input_shape=(32 ** 2,), kernel_initializer=\"he_normal\"))\n",
    "# model_relu_d.add(Activation('relu', name='ReLU_1'))\n",
    "# model_relu_d.add(Dropout(0.2))\n",
    "\n",
    "# model_relu_d.add(Dense(150, kernel_initializer=\"he_normal\"))\n",
    "# model_relu_d.add(Activation('relu', name='ReLU_2'))\n",
    "# model_relu_d.add(Dropout(0.2))\n",
    "\n",
    "# model_relu_d.add(Dense(4))\n",
    "# model_relu_d.add(Activation('softmax'))\n",
    "#----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               307500    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 604       \n",
      "=================================================================\n",
      "Total params: 353,254\n",
      "Trainable params: 353,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_relu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs: \n",
    "input_shape = (32,32,1)\n",
    "learn_rate = 1e-5\n",
    "decay = 0\n",
    "batch_size = 64\n",
    "epochs = 25\n",
    "\n",
    "#Define your optimizar parameters:\n",
    "AdamOpt = Adam(lr=learn_rate,decay=decay)\n",
    "\n",
    "\n",
    "# 28/2/2021 - Not finished: Still need to define paarameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model with the optimizer above, accuracy metric and adequate loss for multiclass task. Train your model on the training set and evaluate the model on the testing set. Print the accuracy and loss over the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6474 samples, validate on 1728 samples\n",
      "Epoch 1/25\n",
      "6474/6474 [==============================] - 2s 274us/sample - loss: 1.3977 - accuracy: 0.3102 - val_loss: 1.2162 - val_accuracy: 0.4873\n",
      "Epoch 2/25\n",
      "6474/6474 [==============================] - 1s 93us/sample - loss: 1.2300 - accuracy: 0.4361 - val_loss: 1.1006 - val_accuracy: 0.5833\n",
      "Epoch 3/25\n",
      "6474/6474 [==============================] - 1s 91us/sample - loss: 1.1386 - accuracy: 0.5111 - val_loss: 1.0248 - val_accuracy: 0.6406\n",
      "Epoch 4/25\n",
      "6474/6474 [==============================] - 1s 101us/sample - loss: 1.0664 - accuracy: 0.5652 - val_loss: 0.9698 - val_accuracy: 0.6777\n",
      "Epoch 5/25\n",
      "6474/6474 [==============================] - 1s 102us/sample - loss: 1.0144 - accuracy: 0.6018 - val_loss: 0.9299 - val_accuracy: 0.7031\n",
      "Epoch 6/25\n",
      "6474/6474 [==============================] - 1s 98us/sample - loss: 0.9808 - accuracy: 0.6236 - val_loss: 0.8968 - val_accuracy: 0.7199\n",
      "Epoch 7/25\n",
      "6474/6474 [==============================] - 1s 105us/sample - loss: 0.9450 - accuracy: 0.6498 - val_loss: 0.8654 - val_accuracy: 0.7350\n",
      "Epoch 8/25\n",
      "6474/6474 [==============================] - 1s 97us/sample - loss: 0.9203 - accuracy: 0.6679 - val_loss: 0.8407 - val_accuracy: 0.7390\n",
      "Epoch 9/25\n",
      "6474/6474 [==============================] - 1s 102us/sample - loss: 0.8814 - accuracy: 0.6877 - val_loss: 0.8169 - val_accuracy: 0.7471\n",
      "Epoch 10/25\n",
      "6474/6474 [==============================] - 1s 98us/sample - loss: 0.8524 - accuracy: 0.7076 - val_loss: 0.7947 - val_accuracy: 0.7529\n",
      "Epoch 11/25\n",
      "6474/6474 [==============================] - 1s 94us/sample - loss: 0.8380 - accuracy: 0.7124 - val_loss: 0.7757 - val_accuracy: 0.7633\n",
      "Epoch 12/25\n",
      "6474/6474 [==============================] - 1s 94us/sample - loss: 0.8219 - accuracy: 0.7230 - val_loss: 0.7579 - val_accuracy: 0.7645\n",
      "Epoch 13/25\n",
      "6474/6474 [==============================] - 1s 97us/sample - loss: 0.8000 - accuracy: 0.7366 - val_loss: 0.7395 - val_accuracy: 0.7703\n",
      "Epoch 14/25\n",
      "6474/6474 [==============================] - 1s 117us/sample - loss: 0.7752 - accuracy: 0.7467 - val_loss: 0.7235 - val_accuracy: 0.7766\n",
      "Epoch 15/25\n",
      "6474/6474 [==============================] - 1s 111us/sample - loss: 0.7709 - accuracy: 0.7447 - val_loss: 0.7084 - val_accuracy: 0.7778\n",
      "Epoch 16/25\n",
      "6474/6474 [==============================] - 1s 115us/sample - loss: 0.7485 - accuracy: 0.7603 - val_loss: 0.6949 - val_accuracy: 0.7824\n",
      "Epoch 17/25\n",
      "6474/6474 [==============================] - 1s 104us/sample - loss: 0.7420 - accuracy: 0.7564 - val_loss: 0.6814 - val_accuracy: 0.7888\n",
      "Epoch 18/25\n",
      "6474/6474 [==============================] - 1s 93us/sample - loss: 0.7221 - accuracy: 0.7563 - val_loss: 0.6689 - val_accuracy: 0.7928\n",
      "Epoch 19/25\n",
      "6474/6474 [==============================] - 1s 97us/sample - loss: 0.7049 - accuracy: 0.7717 - val_loss: 0.6557 - val_accuracy: 0.7969\n",
      "Epoch 20/25\n",
      "6474/6474 [==============================] - 1s 95us/sample - loss: 0.6909 - accuracy: 0.7736 - val_loss: 0.6438 - val_accuracy: 0.8003\n",
      "Epoch 21/25\n",
      "6474/6474 [==============================] - 1s 92us/sample - loss: 0.6796 - accuracy: 0.7813 - val_loss: 0.6331 - val_accuracy: 0.8015\n",
      "Epoch 22/25\n",
      "6474/6474 [==============================] - 1s 93us/sample - loss: 0.6688 - accuracy: 0.7839 - val_loss: 0.6230 - val_accuracy: 0.8084\n",
      "Epoch 23/25\n",
      "6474/6474 [==============================] - 1s 89us/sample - loss: 0.6572 - accuracy: 0.7867 - val_loss: 0.6112 - val_accuracy: 0.8108\n",
      "Epoch 24/25\n",
      "6474/6474 [==============================] - 1s 97us/sample - loss: 0.6467 - accuracy: 0.7896 - val_loss: 0.6015 - val_accuracy: 0.8102\n",
      "Epoch 25/25\n",
      "6474/6474 [==============================] - 1s 93us/sample - loss: 0.6388 - accuracy: 0.7912 - val_loss: 0.5923 - val_accuracy: 0.8154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2134f526488>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "model_relu.compile(optimizer = AdamOpt, metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "model_relu.fit(BaseX_train, BaseY_train, epochs = epochs, batch_size = batch_size, validation_data=(BaseX_val,BaseY_val))\n",
    "\n",
    "# This crossentropy loss function is used when there are two or more label classes. We expect labels to be provided in a one_hot representation. \n",
    "# If labels were  provided as integers, then SparseCategoricalCrossentropy loss should be used. There should be # classes floating point values per feature.\n",
    "#----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 0s 1ms/sample - loss: 0.8077 - accuracy: 0.6857\n",
      "Saved trained model at results/model_relu.h5 \n"
     ]
    }
   ],
   "source": [
    "model_relu.evaluate(X_test, Y_test)\n",
    "\n",
    "# Saving the model:\n",
    "if not(\"results\" in os.listdir()):\n",
    "    os.mkdir(\"results\")\n",
    "save_dir = \"results/\"\n",
    "\n",
    "#model_relu:\n",
    "model_name = \"model_relu.h5\"\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model_relu.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">***Task 2:***</span> *Activation functions.* \n",
    "\n",
    "Change the activation functions to LeakyRelu or tanh or sigmoid. Name the new model `new_a_model`. Explain how it can affect the model.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "#import keras.layers.advanced_activations as advanced_activations\n",
    "leaky_relu = LeakyReLU(alpha=0.1)\n",
    "\n",
    "\n",
    "new_a_model = Sequential()\n",
    "new_a_model.add(Flatten(input_shape = (32,32,1))) #input_shape defines the shape of the input: 32X32 is the image size, while 3 is the number of dimensions (RGB hence 3)\n",
    "new_a_model.add(leaky_relu)\n",
    "new_a_model.add(Dense(n_filters_start,kernel_initializer = he_normal_initializer)) \n",
    "new_a_model.add(leaky_relu)\n",
    "new_a_model.add(Dropout(dropout))\n",
    "new_a_model.add(Dense(n_filters_start/2))\n",
    "new_a_model.add(leaky_relu)\n",
    "new_a_model.add(Dropout(dropout))\n",
    "new_a_model.add(Dense(n_filters_finish)) # 28/2/2021: Might need to be deleted.\n",
    "new_a_model.add(Dense(n_filters_finish,activation='softmax'))\n",
    "\n",
    "new_a_model_25 = new_a_model\n",
    "new_a_model_40 = new_a_model\n",
    "#----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               307500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 604       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 20        \n",
      "=================================================================\n",
      "Total params: 353,274\n",
      "Trainable params: 353,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_a_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">***Task 3:***</span> *Number of epochs.* \n",
    "\n",
    "Train the new model using 25 and 40 epochs. What difference does it makes in term of performance? Remember to save the compiled model for having initialized weights for every run as we did in tutorial 12. Evaluate each trained model on the test set*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs: \n",
    "input_shape = (32,32,1)\n",
    "learn_rate = 1e-5\n",
    "decay = 0\n",
    "batch_size = 64\n",
    "epochs = 25\n",
    "\n",
    "# 28/02/2021: finish the following:\n",
    "#Defining the optimizar parameters:\n",
    "AdamOpt = Adam(lr=learn_rate,decay=decay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6474 samples, validate on 1728 samples\n",
      "Epoch 1/25\n",
      "6474/6474 [==============================] - 1s 224us/sample - loss: 0.2610 - accuracy: 0.9107 - val_loss: 0.2776 - val_accuracy: 0.9097\n",
      "Epoch 2/25\n",
      "6474/6474 [==============================] - 1s 113us/sample - loss: 0.2528 - accuracy: 0.9163 - val_loss: 0.2770 - val_accuracy: 0.9109\n",
      "Epoch 3/25\n",
      "6474/6474 [==============================] - 1s 115us/sample - loss: 0.2599 - accuracy: 0.9116 - val_loss: 0.2774 - val_accuracy: 0.9080\n",
      "Epoch 4/25\n",
      "6474/6474 [==============================] - 1s 104us/sample - loss: 0.2595 - accuracy: 0.9138 - val_loss: 0.2814 - val_accuracy: 0.9080\n",
      "Epoch 5/25\n",
      "6474/6474 [==============================] - 1s 100us/sample - loss: 0.2568 - accuracy: 0.9127 - val_loss: 0.2797 - val_accuracy: 0.9120\n",
      "Epoch 6/25\n",
      "6474/6474 [==============================] - 1s 107us/sample - loss: 0.2533 - accuracy: 0.9137 - val_loss: 0.2776 - val_accuracy: 0.9086\n",
      "Epoch 7/25\n",
      "6474/6474 [==============================] - 1s 97us/sample - loss: 0.2536 - accuracy: 0.9113 - val_loss: 0.2781 - val_accuracy: 0.9097\n",
      "Epoch 8/25\n",
      "6474/6474 [==============================] - 1s 98us/sample - loss: 0.2513 - accuracy: 0.9188 - val_loss: 0.2771 - val_accuracy: 0.9126\n",
      "Epoch 9/25\n",
      "6474/6474 [==============================] - 1s 99us/sample - loss: 0.2436 - accuracy: 0.9200 - val_loss: 0.2815 - val_accuracy: 0.9103\n",
      "Epoch 10/25\n",
      "6474/6474 [==============================] - 1s 100us/sample - loss: 0.2500 - accuracy: 0.9127 - val_loss: 0.2786 - val_accuracy: 0.9103\n",
      "Epoch 11/25\n",
      "6474/6474 [==============================] - 1s 100us/sample - loss: 0.2526 - accuracy: 0.9188 - val_loss: 0.2816 - val_accuracy: 0.9086\n",
      "Epoch 12/25\n",
      "6474/6474 [==============================] - 1s 105us/sample - loss: 0.2523 - accuracy: 0.9184 - val_loss: 0.2783 - val_accuracy: 0.9138\n",
      "Epoch 13/25\n",
      "6474/6474 [==============================] - 1s 98us/sample - loss: 0.2490 - accuracy: 0.9188 - val_loss: 0.2787 - val_accuracy: 0.9103\n",
      "Epoch 14/25\n",
      "6474/6474 [==============================] - 1s 113us/sample - loss: 0.2478 - accuracy: 0.9183 - val_loss: 0.2740 - val_accuracy: 0.9120\n",
      "Epoch 15/25\n",
      "6474/6474 [==============================] - 1s 99us/sample - loss: 0.2504 - accuracy: 0.9137 - val_loss: 0.2723 - val_accuracy: 0.9132\n",
      "Epoch 16/25\n",
      "6474/6474 [==============================] - 1s 97us/sample - loss: 0.2514 - accuracy: 0.9171 - val_loss: 0.2733 - val_accuracy: 0.9138\n",
      "Epoch 17/25\n",
      "6474/6474 [==============================] - 1s 97us/sample - loss: 0.2450 - accuracy: 0.9181 - val_loss: 0.2757 - val_accuracy: 0.9138\n",
      "Epoch 18/25\n",
      "6474/6474 [==============================] - 1s 104us/sample - loss: 0.2457 - accuracy: 0.9172 - val_loss: 0.2733 - val_accuracy: 0.9149\n",
      "Epoch 19/25\n",
      "6474/6474 [==============================] - 1s 98us/sample - loss: 0.2504 - accuracy: 0.9186 - val_loss: 0.2771 - val_accuracy: 0.9109\n",
      "Epoch 20/25\n",
      "6474/6474 [==============================] - 1s 99us/sample - loss: 0.2434 - accuracy: 0.9183 - val_loss: 0.2719 - val_accuracy: 0.9138\n",
      "Epoch 21/25\n",
      "6474/6474 [==============================] - 1s 102us/sample - loss: 0.2440 - accuracy: 0.9181 - val_loss: 0.2706 - val_accuracy: 0.9144\n",
      "Epoch 22/25\n",
      "6474/6474 [==============================] - 1s 110us/sample - loss: 0.2494 - accuracy: 0.9172 - val_loss: 0.2723 - val_accuracy: 0.9144\n",
      "Epoch 23/25\n",
      "6474/6474 [==============================] - 1s 114us/sample - loss: 0.2390 - accuracy: 0.9180 - val_loss: 0.2701 - val_accuracy: 0.9138\n",
      "Epoch 24/25\n",
      "6474/6474 [==============================] - 1s 107us/sample - loss: 0.2472 - accuracy: 0.9172 - val_loss: 0.2733 - val_accuracy: 0.9126\n",
      "Epoch 25/25\n",
      "6474/6474 [==============================] - 1s 108us/sample - loss: 0.2419 - accuracy: 0.9181 - val_loss: 0.2744 - val_accuracy: 0.9132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2134080c808>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "new_a_model_25.compile(optimizer = AdamOpt, metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "new_a_model_25.fit(BaseX_train, BaseY_train, epochs = epochs, batch_size = batch_size, validation_data=(BaseX_val,BaseY_val))\n",
    "#-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs: \n",
    "input_shape = (32,32,1)\n",
    "learn_rate = 1e-5\n",
    "decay = 0\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "\n",
    "#Defining the optimizar parameters:\n",
    "AdamOpt = Adam(lr=learn_rate,decay=decay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation results 25 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 0s 137us/sample - loss: 0.9819 - accuracy: 0.6514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9819434193202428, 0.6514286]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_a_model_25.evaluate(X_test, Y_test)\n",
    "\n",
    "# Saving the model:\n",
    "#new_a_model - 25 epochs:\n",
    "model_name = \"new_a_model_25.h5\"\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "new_a_model_25.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6474 samples, validate on 1728 samples\n",
      "Epoch 1/40\n",
      "6474/6474 [==============================] - 1s 225us/sample - loss: 0.2220 - accuracy: 0.9203 - val_loss: 0.2535 - val_accuracy: 0.9184\n",
      "Epoch 2/40\n",
      "6474/6474 [==============================] - 1s 102us/sample - loss: 0.2200 - accuracy: 0.9229 - val_loss: 0.2528 - val_accuracy: 0.9196\n",
      "Epoch 3/40\n",
      "6474/6474 [==============================] - 1s 103us/sample - loss: 0.2155 - accuracy: 0.9268 - val_loss: 0.2488 - val_accuracy: 0.9172\n",
      "Epoch 4/40\n",
      "6474/6474 [==============================] - 1s 99us/sample - loss: 0.2220 - accuracy: 0.9235 - val_loss: 0.2530 - val_accuracy: 0.9190\n",
      "Epoch 5/40\n",
      "6474/6474 [==============================] - 1s 100us/sample - loss: 0.2180 - accuracy: 0.9291 - val_loss: 0.2571 - val_accuracy: 0.9207\n",
      "Epoch 6/40\n",
      "6474/6474 [==============================] - 1s 100us/sample - loss: 0.2176 - accuracy: 0.9282 - val_loss: 0.2503 - val_accuracy: 0.9219\n",
      "Epoch 7/40\n",
      "6474/6474 [==============================] - 1s 97us/sample - loss: 0.2256 - accuracy: 0.9226 - val_loss: 0.2513 - val_accuracy: 0.9207\n",
      "Epoch 8/40\n",
      "6474/6474 [==============================] - 1s 101us/sample - loss: 0.2186 - accuracy: 0.9266 - val_loss: 0.2532 - val_accuracy: 0.9184\n",
      "Epoch 9/40\n",
      "6474/6474 [==============================] - 1s 102us/sample - loss: 0.2199 - accuracy: 0.9263 - val_loss: 0.2488 - val_accuracy: 0.9196\n",
      "Epoch 10/40\n",
      "6474/6474 [==============================] - 1s 98us/sample - loss: 0.2112 - accuracy: 0.9288 - val_loss: 0.2522 - val_accuracy: 0.9178\n",
      "Epoch 11/40\n",
      "6474/6474 [==============================] - 1s 98us/sample - loss: 0.2127 - accuracy: 0.9302 - val_loss: 0.2507 - val_accuracy: 0.9201\n",
      "Epoch 12/40\n",
      "6474/6474 [==============================] - 1s 103us/sample - loss: 0.2105 - accuracy: 0.9297 - val_loss: 0.2499 - val_accuracy: 0.9207\n",
      "Epoch 13/40\n",
      "6474/6474 [==============================] - 1s 102us/sample - loss: 0.2186 - accuracy: 0.9272 - val_loss: 0.2491 - val_accuracy: 0.9201\n",
      "Epoch 14/40\n",
      "6474/6474 [==============================] - 1s 98us/sample - loss: 0.2195 - accuracy: 0.9245 - val_loss: 0.2515 - val_accuracy: 0.9207\n",
      "Epoch 15/40\n",
      "6474/6474 [==============================] - 1s 107us/sample - loss: 0.2184 - accuracy: 0.9277 - val_loss: 0.2514 - val_accuracy: 0.9201\n",
      "Epoch 16/40\n",
      "6474/6474 [==============================] - 1s 102us/sample - loss: 0.2162 - accuracy: 0.9266 - val_loss: 0.2484 - val_accuracy: 0.9201\n",
      "Epoch 17/40\n",
      "6474/6474 [==============================] - 1s 98us/sample - loss: 0.2137 - accuracy: 0.9277 - val_loss: 0.2474 - val_accuracy: 0.9213\n",
      "Epoch 18/40\n",
      "6474/6474 [==============================] - 1s 100us/sample - loss: 0.2102 - accuracy: 0.9297 - val_loss: 0.2492 - val_accuracy: 0.9190\n",
      "Epoch 19/40\n",
      "6474/6474 [==============================] - 1s 98us/sample - loss: 0.2214 - accuracy: 0.9237 - val_loss: 0.2501 - val_accuracy: 0.9213\n",
      "Epoch 20/40\n",
      "6474/6474 [==============================] - 1s 98us/sample - loss: 0.2097 - accuracy: 0.9293 - val_loss: 0.2590 - val_accuracy: 0.9167\n",
      "Epoch 21/40\n",
      "6474/6474 [==============================] - 1s 103us/sample - loss: 0.2070 - accuracy: 0.9269 - val_loss: 0.2559 - val_accuracy: 0.9196\n",
      "Epoch 22/40\n",
      "6474/6474 [==============================] - 1s 99us/sample - loss: 0.2120 - accuracy: 0.9260 - val_loss: 0.2476 - val_accuracy: 0.9213\n",
      "Epoch 23/40\n",
      "6474/6474 [==============================] - 1s 103us/sample - loss: 0.2139 - accuracy: 0.9254 - val_loss: 0.2516 - val_accuracy: 0.9201\n",
      "Epoch 24/40\n",
      "6474/6474 [==============================] - 1s 114us/sample - loss: 0.2118 - accuracy: 0.9279 - val_loss: 0.2544 - val_accuracy: 0.9196\n",
      "Epoch 25/40\n",
      "6474/6474 [==============================] - 1s 104us/sample - loss: 0.2070 - accuracy: 0.9288 - val_loss: 0.2528 - val_accuracy: 0.9207\n",
      "Epoch 26/40\n",
      "6474/6474 [==============================] - 1s 109us/sample - loss: 0.2024 - accuracy: 0.9337 - val_loss: 0.2466 - val_accuracy: 0.9190\n",
      "Epoch 27/40\n",
      "6474/6474 [==============================] - 1s 107us/sample - loss: 0.2039 - accuracy: 0.9310 - val_loss: 0.2493 - val_accuracy: 0.9201\n",
      "Epoch 28/40\n",
      "6474/6474 [==============================] - 1s 108us/sample - loss: 0.2070 - accuracy: 0.9322 - val_loss: 0.2477 - val_accuracy: 0.9201\n",
      "Epoch 29/40\n",
      "6474/6474 [==============================] - 1s 111us/sample - loss: 0.2123 - accuracy: 0.9289 - val_loss: 0.2457 - val_accuracy: 0.9219\n",
      "Epoch 30/40\n",
      "6474/6474 [==============================] - 1s 109us/sample - loss: 0.2110 - accuracy: 0.9310 - val_loss: 0.2505 - val_accuracy: 0.9196\n",
      "Epoch 31/40\n",
      "6474/6474 [==============================] - 1s 107us/sample - loss: 0.2068 - accuracy: 0.9302 - val_loss: 0.2504 - val_accuracy: 0.9201\n",
      "Epoch 32/40\n",
      "6474/6474 [==============================] - 1s 106us/sample - loss: 0.2130 - accuracy: 0.9291 - val_loss: 0.2468 - val_accuracy: 0.9207\n",
      "Epoch 33/40\n",
      "6474/6474 [==============================] - 1s 104us/sample - loss: 0.2081 - accuracy: 0.9274 - val_loss: 0.2475 - val_accuracy: 0.9190\n",
      "Epoch 34/40\n",
      "6474/6474 [==============================] - 1s 106us/sample - loss: 0.2073 - accuracy: 0.9286 - val_loss: 0.2464 - val_accuracy: 0.9201\n",
      "Epoch 35/40\n",
      "6474/6474 [==============================] - 1s 105us/sample - loss: 0.2037 - accuracy: 0.9289 - val_loss: 0.2441 - val_accuracy: 0.9225\n",
      "Epoch 36/40\n",
      "6474/6474 [==============================] - 1s 103us/sample - loss: 0.2062 - accuracy: 0.9268 - val_loss: 0.2493 - val_accuracy: 0.9196\n",
      "Epoch 37/40\n",
      "6474/6474 [==============================] - 1s 99us/sample - loss: 0.2042 - accuracy: 0.9302 - val_loss: 0.2472 - val_accuracy: 0.9213\n",
      "Epoch 38/40\n",
      "6474/6474 [==============================] - 1s 103us/sample - loss: 0.2057 - accuracy: 0.9308 - val_loss: 0.2439 - val_accuracy: 0.9207\n",
      "Epoch 39/40\n",
      "6474/6474 [==============================] - 1s 104us/sample - loss: 0.2093 - accuracy: 0.9277 - val_loss: 0.2442 - val_accuracy: 0.9207\n",
      "Epoch 40/40\n",
      "6474/6474 [==============================] - 1s 105us/sample - loss: 0.2023 - accuracy: 0.9305 - val_loss: 0.2447 - val_accuracy: 0.9201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2134254a0c8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "\n",
    "new_a_model_40.compile(optimizer = AdamOpt, metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "new_a_model_40.fit(BaseX_train, BaseY_train, epochs = epochs, batch_size = batch_size, validation_data=(BaseX_val,BaseY_val))\n",
    "\n",
    "#-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation results 40 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 0s 1ms/sample - loss: 1.0150 - accuracy: 0.6457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0150217856679644, 0.6457143]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_a_model_40.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at results/new_a_model_40.h5 \n"
     ]
    }
   ],
   "source": [
    "# Saving the model:\n",
    "#new_a_model - 40 epochs:\n",
    "model_name = \"new_a_model_40.h5\"\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "new_a_model_40.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">***Task 4:***</span> *Mini-batches.* \n",
    "\n",
    "Build the `model_relu` again and run it with a batch size of 32 instead of 64. What are the advantages of the mini-batch vs. SGD?*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "# original 64 batch-size model:\n",
    "model_relu_32b = Sequential()\n",
    "model_relu_32b.add(Flatten(input_shape = (32,32,1))) #input_shape defines the shape of the input: 32X32 is the image size, while 3 is the number of dimensions (RGB hence 3)\n",
    "model_relu_32b.add(Dense(n_filters_start, activation='relu',kernel_initializer = he_normal_initializer)) \n",
    "model_relu_32b.add(Dropout(dropout))\n",
    "model_relu_32b.add(Dense(n_filters_start/2,activation='relu'))\n",
    "model_relu_32b.add(Dropout(dropout))\n",
    "model_relu_32b.add(Dense(n_filters_finish,activation='softmax'))\n",
    "\n",
    "#----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "#Define your optimizar parameters:\n",
    "AdamOpt = Adam(lr=learn_rate,decay=decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6474 samples, validate on 1728 samples\n",
      "Epoch 1/50\n",
      "6474/6474 [==============================] - 2s 301us/sample - loss: 1.3365 - accuracy: 0.3488 - val_loss: 1.1782 - val_accuracy: 0.5700\n",
      "Epoch 2/50\n",
      "6474/6474 [==============================] - 1s 161us/sample - loss: 1.1655 - accuracy: 0.5074 - val_loss: 1.0561 - val_accuracy: 0.6429\n",
      "Epoch 3/50\n",
      "6474/6474 [==============================] - 1s 173us/sample - loss: 1.0722 - accuracy: 0.5789 - val_loss: 0.9852 - val_accuracy: 0.6863\n",
      "Epoch 4/50\n",
      "6474/6474 [==============================] - 1s 183us/sample - loss: 1.0182 - accuracy: 0.6143 - val_loss: 0.9349 - val_accuracy: 0.6991\n",
      "Epoch 5/50\n",
      "6474/6474 [==============================] - 1s 164us/sample - loss: 0.9668 - accuracy: 0.6412 - val_loss: 0.8892 - val_accuracy: 0.7228\n",
      "Epoch 6/50\n",
      "6474/6474 [==============================] - 1s 163us/sample - loss: 0.9285 - accuracy: 0.6616 - val_loss: 0.8541 - val_accuracy: 0.7436\n",
      "Epoch 7/50\n",
      "6474/6474 [==============================] - 1s 159us/sample - loss: 0.8860 - accuracy: 0.6874 - val_loss: 0.8204 - val_accuracy: 0.7477\n",
      "Epoch 8/50\n",
      "6474/6474 [==============================] - 1s 167us/sample - loss: 0.8583 - accuracy: 0.7056 - val_loss: 0.7931 - val_accuracy: 0.7494\n",
      "Epoch 9/50\n",
      "6474/6474 [==============================] - 1s 174us/sample - loss: 0.8363 - accuracy: 0.7090 - val_loss: 0.7702 - val_accuracy: 0.7616\n",
      "Epoch 10/50\n",
      "6474/6474 [==============================] - 1s 183us/sample - loss: 0.8082 - accuracy: 0.7223 - val_loss: 0.7452 - val_accuracy: 0.7674\n",
      "Epoch 11/50\n",
      "6474/6474 [==============================] - 1s 190us/sample - loss: 0.7867 - accuracy: 0.7275 - val_loss: 0.7219 - val_accuracy: 0.7668\n",
      "Epoch 12/50\n",
      "6474/6474 [==============================] - 1s 165us/sample - loss: 0.7615 - accuracy: 0.7383 - val_loss: 0.7047 - val_accuracy: 0.7784\n",
      "Epoch 13/50\n",
      "6474/6474 [==============================] - 1s 168us/sample - loss: 0.7387 - accuracy: 0.7553 - val_loss: 0.6853 - val_accuracy: 0.7836\n",
      "Epoch 14/50\n",
      "6474/6474 [==============================] - 1s 166us/sample - loss: 0.7163 - accuracy: 0.7660 - val_loss: 0.6656 - val_accuracy: 0.7922\n",
      "Epoch 15/50\n",
      "6474/6474 [==============================] - 1s 179us/sample - loss: 0.7035 - accuracy: 0.7665 - val_loss: 0.6480 - val_accuracy: 0.7899\n",
      "Epoch 16/50\n",
      "6474/6474 [==============================] - 1s 165us/sample - loss: 0.6847 - accuracy: 0.7776 - val_loss: 0.6326 - val_accuracy: 0.7975\n",
      "Epoch 17/50\n",
      "6474/6474 [==============================] - 1s 161us/sample - loss: 0.6719 - accuracy: 0.7780 - val_loss: 0.6204 - val_accuracy: 0.8021\n",
      "Epoch 18/50\n",
      "6474/6474 [==============================] - 1s 152us/sample - loss: 0.6507 - accuracy: 0.7912 - val_loss: 0.6045 - val_accuracy: 0.8102\n",
      "Epoch 19/50\n",
      "6474/6474 [==============================] - 1s 164us/sample - loss: 0.6378 - accuracy: 0.7910 - val_loss: 0.5926 - val_accuracy: 0.8108\n",
      "Epoch 20/50\n",
      "6474/6474 [==============================] - 1s 152us/sample - loss: 0.6223 - accuracy: 0.7952 - val_loss: 0.5804 - val_accuracy: 0.8131\n",
      "Epoch 21/50\n",
      "6474/6474 [==============================] - 1s 156us/sample - loss: 0.6075 - accuracy: 0.8020 - val_loss: 0.5664 - val_accuracy: 0.8206\n",
      "Epoch 22/50\n",
      "6474/6474 [==============================] - 1s 160us/sample - loss: 0.6006 - accuracy: 0.8037 - val_loss: 0.5573 - val_accuracy: 0.8235\n",
      "Epoch 23/50\n",
      "6474/6474 [==============================] - 1s 154us/sample - loss: 0.5927 - accuracy: 0.8046 - val_loss: 0.5469 - val_accuracy: 0.8275\n",
      "Epoch 24/50\n",
      "6474/6474 [==============================] - 1s 172us/sample - loss: 0.5761 - accuracy: 0.8088 - val_loss: 0.5352 - val_accuracy: 0.8316\n",
      "Epoch 25/50\n",
      "6474/6474 [==============================] - 1s 164us/sample - loss: 0.5631 - accuracy: 0.8139 - val_loss: 0.5272 - val_accuracy: 0.8328\n",
      "Epoch 26/50\n",
      "6474/6474 [==============================] - 1s 159us/sample - loss: 0.5473 - accuracy: 0.8188 - val_loss: 0.5188 - val_accuracy: 0.8356\n",
      "Epoch 27/50\n",
      "6474/6474 [==============================] - 1s 163us/sample - loss: 0.5416 - accuracy: 0.8185 - val_loss: 0.5084 - val_accuracy: 0.8385\n",
      "Epoch 28/50\n",
      "6474/6474 [==============================] - 1s 155us/sample - loss: 0.5367 - accuracy: 0.8182 - val_loss: 0.5014 - val_accuracy: 0.8409\n",
      "Epoch 29/50\n",
      "6474/6474 [==============================] - 1s 170us/sample - loss: 0.5188 - accuracy: 0.8268 - val_loss: 0.4941 - val_accuracy: 0.8414\n",
      "Epoch 30/50\n",
      "6474/6474 [==============================] - 1s 184us/sample - loss: 0.5223 - accuracy: 0.8281 - val_loss: 0.4846 - val_accuracy: 0.8432\n",
      "Epoch 31/50\n",
      "6474/6474 [==============================] - 1s 170us/sample - loss: 0.5104 - accuracy: 0.8336 - val_loss: 0.4785 - val_accuracy: 0.8466\n",
      "Epoch 32/50\n",
      "6474/6474 [==============================] - 1s 172us/sample - loss: 0.5019 - accuracy: 0.8338 - val_loss: 0.4720 - val_accuracy: 0.8461\n",
      "Epoch 33/50\n",
      "6474/6474 [==============================] - 1s 168us/sample - loss: 0.4929 - accuracy: 0.8401 - val_loss: 0.4649 - val_accuracy: 0.8466\n",
      "Epoch 34/50\n",
      "6474/6474 [==============================] - 1s 159us/sample - loss: 0.4876 - accuracy: 0.8429 - val_loss: 0.4623 - val_accuracy: 0.8513\n",
      "Epoch 35/50\n",
      "6474/6474 [==============================] - 1s 180us/sample - loss: 0.4765 - accuracy: 0.8440 - val_loss: 0.4540 - val_accuracy: 0.8542\n",
      "Epoch 36/50\n",
      "6474/6474 [==============================] - 1s 187us/sample - loss: 0.4645 - accuracy: 0.8542 - val_loss: 0.4456 - val_accuracy: 0.8553\n",
      "Epoch 37/50\n",
      "6474/6474 [==============================] - 1s 187us/sample - loss: 0.4636 - accuracy: 0.8480 - val_loss: 0.4393 - val_accuracy: 0.8542\n",
      "Epoch 38/50\n",
      "6474/6474 [==============================] - 1s 169us/sample - loss: 0.4594 - accuracy: 0.8503 - val_loss: 0.4356 - val_accuracy: 0.8576\n",
      "Epoch 39/50\n",
      "6474/6474 [==============================] - 1s 168us/sample - loss: 0.4548 - accuracy: 0.8503 - val_loss: 0.4291 - val_accuracy: 0.8571\n",
      "Epoch 40/50\n",
      "6474/6474 [==============================] - 1s 164us/sample - loss: 0.4491 - accuracy: 0.8509 - val_loss: 0.4247 - val_accuracy: 0.8640\n",
      "Epoch 41/50\n",
      "6474/6474 [==============================] - 1s 165us/sample - loss: 0.4471 - accuracy: 0.8508 - val_loss: 0.4210 - val_accuracy: 0.8623\n",
      "Epoch 42/50\n",
      "6474/6474 [==============================] - 1s 168us/sample - loss: 0.4306 - accuracy: 0.8630 - val_loss: 0.4174 - val_accuracy: 0.8646\n",
      "Epoch 43/50\n",
      "6474/6474 [==============================] - 1s 164us/sample - loss: 0.4317 - accuracy: 0.8591 - val_loss: 0.4128 - val_accuracy: 0.8634\n",
      "Epoch 44/50\n",
      "6474/6474 [==============================] - 1s 174us/sample - loss: 0.4246 - accuracy: 0.8641 - val_loss: 0.4098 - val_accuracy: 0.8646\n",
      "Epoch 45/50\n",
      "6474/6474 [==============================] - 1s 169us/sample - loss: 0.4214 - accuracy: 0.8625 - val_loss: 0.4019 - val_accuracy: 0.8669\n",
      "Epoch 46/50\n",
      "6474/6474 [==============================] - 1s 160us/sample - loss: 0.4167 - accuracy: 0.8659 - val_loss: 0.4010 - val_accuracy: 0.8681\n",
      "Epoch 47/50\n",
      "6474/6474 [==============================] - 1s 170us/sample - loss: 0.4100 - accuracy: 0.8689 - val_loss: 0.3962 - val_accuracy: 0.8715\n",
      "Epoch 48/50\n",
      "6474/6474 [==============================] - 1s 161us/sample - loss: 0.4104 - accuracy: 0.8591 - val_loss: 0.3951 - val_accuracy: 0.8791\n",
      "Epoch 49/50\n",
      "6474/6474 [==============================] - 1s 160us/sample - loss: 0.4009 - accuracy: 0.8689 - val_loss: 0.3875 - val_accuracy: 0.8779\n",
      "Epoch 50/50\n",
      "6474/6474 [==============================] - 1s 161us/sample - loss: 0.4020 - accuracy: 0.8698 - val_loss: 0.3896 - val_accuracy: 0.8796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21343cdee08>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "model_relu_32b.compile(optimizer = AdamOpt, metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "model_relu_32b.fit(BaseX_train, BaseY_train, epochs = epochs, batch_size = batch_size, validation_data=(BaseX_val,BaseY_val))\n",
    "#----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 0s 1ms/sample - loss: 0.8402 - accuracy: 0.6629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8402193890299116, 0.6628571]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_relu_32b.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">***Task 4:***</span> *Batch normalization.* \n",
    "\n",
    "Build the `new_a_model` again and add batch normalization layers. How does it impact your results?*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "# 28/02/2021: Make sure that BatchNormaliztion() does not need any parameters:\n",
    "new_a_model_batch = Sequential()\n",
    "new_a_model_batch.add(Flatten(input_shape = (32,32,1))) #input_shape defines the shape of the input: 32X32 is the image size, while 3 is the number of dimensions (RGB hence 3)\n",
    "new_a_model_batch.add(leaky_relu)\n",
    "new_a_model_batch.add(BatchNormalization())\n",
    "new_a_model_batch.add(Dense(n_filters_start,kernel_initializer = he_normal_initializer)) \n",
    "new_a_model_batch.add(leaky_relu)\n",
    "new_a_model_batch.add(BatchNormalization())\n",
    "new_a_model_batch.add(Dropout(dropout))\n",
    "new_a_model_batch.add(BatchNormalization())\n",
    "new_a_model_batch.add(Dense(n_filters_start/2))\n",
    "new_a_model_batch.add(leaky_relu)\n",
    "new_a_model_batch.add(BatchNormalization())\n",
    "new_a_model_batch.add(Dropout(dropout))\n",
    "new_a_model_batch.add(BatchNormalization())\n",
    "new_a_model_batch.add(Dense(n_filters_finish))\n",
    "new_a_model_batch.add(BatchNormalization())\n",
    "new_a_model_batch.add(Dense(n_filters_finish,activation='softmax'))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "#Define your optimizar parameters:\n",
    "AdamOpt = Adam(lr=learn_rate,decay=decay)\n",
    "#Compile the network: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6474 samples, validate on 1728 samples\n",
      "Epoch 1/50\n",
      "6474/6474 [==============================] - 4s 588us/sample - loss: 1.3162 - accuracy: 0.4296 - val_loss: 1.1608 - val_accuracy: 0.5324\n",
      "Epoch 2/50\n",
      "6474/6474 [==============================] - 2s 279us/sample - loss: 1.0431 - accuracy: 0.5666 - val_loss: 0.9173 - val_accuracy: 0.6742\n",
      "Epoch 3/50\n",
      "6474/6474 [==============================] - 2s 301us/sample - loss: 0.9400 - accuracy: 0.6373 - val_loss: 0.8124 - val_accuracy: 0.7413\n",
      "Epoch 4/50\n",
      "6474/6474 [==============================] - 2s 283us/sample - loss: 0.8866 - accuracy: 0.6833 - val_loss: 0.7633 - val_accuracy: 0.7836\n",
      "Epoch 5/50\n",
      "6474/6474 [==============================] - 2s 297us/sample - loss: 0.8513 - accuracy: 0.7088 - val_loss: 0.7355 - val_accuracy: 0.8038\n",
      "Epoch 6/50\n",
      "6474/6474 [==============================] - 2s 278us/sample - loss: 0.8287 - accuracy: 0.7373 - val_loss: 0.7105 - val_accuracy: 0.8171\n",
      "Epoch 7/50\n",
      "6474/6474 [==============================] - 2s 293us/sample - loss: 0.7946 - accuracy: 0.7576 - val_loss: 0.6964 - val_accuracy: 0.8287\n",
      "Epoch 8/50\n",
      "6474/6474 [==============================] - 2s 290us/sample - loss: 0.7816 - accuracy: 0.7677 - val_loss: 0.6761 - val_accuracy: 0.8385\n",
      "Epoch 9/50\n",
      "6474/6474 [==============================] - 2s 275us/sample - loss: 0.7607 - accuracy: 0.7785 - val_loss: 0.6648 - val_accuracy: 0.8472\n",
      "Epoch 10/50\n",
      "6474/6474 [==============================] - 2s 289us/sample - loss: 0.7543 - accuracy: 0.7853 - val_loss: 0.6490 - val_accuracy: 0.8530\n",
      "Epoch 11/50\n",
      "6474/6474 [==============================] - 2s 281us/sample - loss: 0.7342 - accuracy: 0.8027 - val_loss: 0.6366 - val_accuracy: 0.8594\n",
      "Epoch 12/50\n",
      "6474/6474 [==============================] - 2s 277us/sample - loss: 0.7225 - accuracy: 0.8007 - val_loss: 0.6289 - val_accuracy: 0.8663\n",
      "Epoch 13/50\n",
      "6474/6474 [==============================] - 2s 283us/sample - loss: 0.7145 - accuracy: 0.8157 - val_loss: 0.6185 - val_accuracy: 0.8669\n",
      "Epoch 14/50\n",
      "6474/6474 [==============================] - 2s 291us/sample - loss: 0.7066 - accuracy: 0.8143 - val_loss: 0.6078 - val_accuracy: 0.8727\n",
      "Epoch 15/50\n",
      "6474/6474 [==============================] - 2s 279us/sample - loss: 0.6947 - accuracy: 0.8185 - val_loss: 0.5995 - val_accuracy: 0.8738\n",
      "Epoch 16/50\n",
      "6474/6474 [==============================] - 2s 293us/sample - loss: 0.6855 - accuracy: 0.8264 - val_loss: 0.5949 - val_accuracy: 0.8767\n",
      "Epoch 17/50\n",
      "6474/6474 [==============================] - 2s 298us/sample - loss: 0.6770 - accuracy: 0.8309 - val_loss: 0.5855 - val_accuracy: 0.8796\n",
      "Epoch 18/50\n",
      "6474/6474 [==============================] - 2s 306us/sample - loss: 0.6685 - accuracy: 0.8352 - val_loss: 0.5783 - val_accuracy: 0.8796\n",
      "Epoch 19/50\n",
      "6474/6474 [==============================] - 2s 282us/sample - loss: 0.6567 - accuracy: 0.8457 - val_loss: 0.5737 - val_accuracy: 0.8819\n",
      "Epoch 20/50\n",
      "6474/6474 [==============================] - 2s 283us/sample - loss: 0.6559 - accuracy: 0.8431 - val_loss: 0.5689 - val_accuracy: 0.8854\n",
      "Epoch 21/50\n",
      "6474/6474 [==============================] - 2s 306us/sample - loss: 0.6469 - accuracy: 0.8485 - val_loss: 0.5626 - val_accuracy: 0.8843\n",
      "Epoch 22/50\n",
      "6474/6474 [==============================] - 2s 305us/sample - loss: 0.6524 - accuracy: 0.8440 - val_loss: 0.5580 - val_accuracy: 0.8889\n",
      "Epoch 23/50\n",
      "6474/6474 [==============================] - 2s 289us/sample - loss: 0.6436 - accuracy: 0.8472 - val_loss: 0.5524 - val_accuracy: 0.8906\n",
      "Epoch 24/50\n",
      "6474/6474 [==============================] - 2s 317us/sample - loss: 0.6291 - accuracy: 0.8540 - val_loss: 0.5459 - val_accuracy: 0.8924\n",
      "Epoch 25/50\n",
      "6474/6474 [==============================] - 2s 287us/sample - loss: 0.6271 - accuracy: 0.8489 - val_loss: 0.5423 - val_accuracy: 0.8889\n",
      "Epoch 26/50\n",
      "6474/6474 [==============================] - 2s 293us/sample - loss: 0.6248 - accuracy: 0.8477 - val_loss: 0.5382 - val_accuracy: 0.8935\n",
      "Epoch 27/50\n",
      "6474/6474 [==============================] - 2s 285us/sample - loss: 0.6151 - accuracy: 0.8567 - val_loss: 0.5322 - val_accuracy: 0.8941\n",
      "Epoch 28/50\n",
      "6474/6474 [==============================] - 2s 286us/sample - loss: 0.6086 - accuracy: 0.8590 - val_loss: 0.5259 - val_accuracy: 0.8958\n",
      "Epoch 29/50\n",
      "6474/6474 [==============================] - 2s 288us/sample - loss: 0.6041 - accuracy: 0.8590 - val_loss: 0.5225 - val_accuracy: 0.8958\n",
      "Epoch 30/50\n",
      "6474/6474 [==============================] - 2s 288us/sample - loss: 0.6072 - accuracy: 0.8601 - val_loss: 0.5183 - val_accuracy: 0.8970\n",
      "Epoch 31/50\n",
      "6474/6474 [==============================] - 2s 306us/sample - loss: 0.5924 - accuracy: 0.8676 - val_loss: 0.5164 - val_accuracy: 0.8999\n",
      "Epoch 32/50\n",
      "6474/6474 [==============================] - 2s 301us/sample - loss: 0.5860 - accuracy: 0.8662 - val_loss: 0.5111 - val_accuracy: 0.8947\n",
      "Epoch 33/50\n",
      "6474/6474 [==============================] - 2s 293us/sample - loss: 0.5782 - accuracy: 0.8704 - val_loss: 0.5085 - val_accuracy: 0.8958\n",
      "Epoch 34/50\n",
      "6474/6474 [==============================] - 2s 291us/sample - loss: 0.5835 - accuracy: 0.8665 - val_loss: 0.5001 - val_accuracy: 0.8999\n",
      "Epoch 35/50\n",
      "6474/6474 [==============================] - 2s 284us/sample - loss: 0.5754 - accuracy: 0.8684 - val_loss: 0.4999 - val_accuracy: 0.8993\n",
      "Epoch 36/50\n",
      "6474/6474 [==============================] - 2s 293us/sample - loss: 0.5723 - accuracy: 0.8706 - val_loss: 0.4945 - val_accuracy: 0.8993\n",
      "Epoch 37/50\n",
      "6474/6474 [==============================] - 2s 302us/sample - loss: 0.5727 - accuracy: 0.8704 - val_loss: 0.4923 - val_accuracy: 0.8981\n",
      "Epoch 38/50\n",
      "6474/6474 [==============================] - 2s 285us/sample - loss: 0.5611 - accuracy: 0.8758 - val_loss: 0.4870 - val_accuracy: 0.9005\n",
      "Epoch 39/50\n",
      "6474/6474 [==============================] - 2s 292us/sample - loss: 0.5579 - accuracy: 0.8727 - val_loss: 0.4825 - val_accuracy: 0.8976\n",
      "Epoch 40/50\n",
      "6474/6474 [==============================] - 2s 295us/sample - loss: 0.5512 - accuracy: 0.8825 - val_loss: 0.4877 - val_accuracy: 0.8987\n",
      "Epoch 41/50\n",
      "6474/6474 [==============================] - 2s 290us/sample - loss: 0.5503 - accuracy: 0.8834 - val_loss: 0.4798 - val_accuracy: 0.8993\n",
      "Epoch 42/50\n",
      "6474/6474 [==============================] - 2s 300us/sample - loss: 0.5481 - accuracy: 0.8749 - val_loss: 0.4768 - val_accuracy: 0.9010\n",
      "Epoch 43/50\n",
      "6474/6474 [==============================] - 2s 304us/sample - loss: 0.5393 - accuracy: 0.8852 - val_loss: 0.4750 - val_accuracy: 0.9022\n",
      "Epoch 44/50\n",
      "6474/6474 [==============================] - 2s 297us/sample - loss: 0.5374 - accuracy: 0.8840 - val_loss: 0.4721 - val_accuracy: 0.8993\n",
      "Epoch 45/50\n",
      "6474/6474 [==============================] - 2s 287us/sample - loss: 0.5360 - accuracy: 0.8855 - val_loss: 0.4676 - val_accuracy: 0.9010\n",
      "Epoch 46/50\n",
      "6474/6474 [==============================] - 2s 285us/sample - loss: 0.5346 - accuracy: 0.8792 - val_loss: 0.4639 - val_accuracy: 0.9045\n",
      "Epoch 47/50\n",
      "6474/6474 [==============================] - 2s 289us/sample - loss: 0.5296 - accuracy: 0.8840 - val_loss: 0.4639 - val_accuracy: 0.9057\n",
      "Epoch 48/50\n",
      "6474/6474 [==============================] - 2s 296us/sample - loss: 0.5238 - accuracy: 0.8857 - val_loss: 0.4602 - val_accuracy: 0.9045\n",
      "Epoch 49/50\n",
      "6474/6474 [==============================] - 2s 292us/sample - loss: 0.5198 - accuracy: 0.8923 - val_loss: 0.4547 - val_accuracy: 0.9051\n",
      "Epoch 50/50\n",
      "6474/6474 [==============================] - 2s 295us/sample - loss: 0.5208 - accuracy: 0.8838 - val_loss: 0.4533 - val_accuracy: 0.9045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2134450af88>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preforming the training by using fit \n",
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "new_a_model_batch.compile(optimizer = AdamOpt, metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "new_a_model_batch.fit(BaseX_train, BaseY_train, epochs = epochs, batch_size = batch_size, validation_data=(BaseX_val,BaseY_val))\n",
    "#----------------------------------------------------------------------------------------\n",
    "# 28/02/2021: add evaluate()!!! and answer the question: \"How does it impact your results?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 0s 2ms/sample - loss: 0.8493 - accuracy: 0.6971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.849312767301287, 0.69714284]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_a_model_batch.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at results/model_relu_32.h5 \n",
      "Saved trained model at results/new_a_model_batch_norm.h5 \n"
     ]
    }
   ],
   "source": [
    "#model_relu - batch = 32:\n",
    "model_name = \"model_relu_32.h5\"\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model_relu_32b.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "#new_a_model - with batch normalization:\n",
    "model_name = \"new_a_model_batch_norm.h5\"\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "new_a_model_batch.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 2: Convolutional Neural Network (CNN)\n",
    "------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">***Task 1:***</span> *2D CNN.* \n",
    "\n",
    "Have a look at the model below and answer the following:\n",
    "* How many layers does it have?\n",
    "* How many filter in each layer?\n",
    "* Would the number of parmaters be similar to a fully connected NN?\n",
    "* Is this specific NN performing regularization?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(input_shape,drop,dropRate,reg):\n",
    "    #Defining the network architecture:\n",
    "    model = Sequential()\n",
    "    model.add(Permute((1,2,3),input_shape = input_shape))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu',name='Conv2D_1',kernel_regularizer=regularizers.l2(reg)))\n",
    "    if drop:\n",
    "        model.add(Dropout(rate=dropRate))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu',name='Conv2D_2',kernel_regularizer=regularizers.l2(reg)))\n",
    "    if drop:    \n",
    "        model.add(Dropout(rate=dropRate))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu',name='Conv2D_3',kernel_regularizer=regularizers.l2(reg)))\n",
    "    if drop:\n",
    "        model.add(Dropout(rate=dropRate))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu',name='Conv2D_4',kernel_regularizer=regularizers.l2(reg)))\n",
    "    if drop:\n",
    "        model.add(Dropout(rate=dropRate))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu',name='Conv2D_5',kernel_regularizer=regularizers.l2(reg)))\n",
    "    if drop:\n",
    "        model.add(Dropout(rate=dropRate))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    #Fully connected network tail:      \n",
    "    model.add(Dense(512, activation='elu',name='FCN_1')) \n",
    "    if drop:\n",
    "        model.add(Dropout(rate=dropRate))\n",
    "    model.add(Dense(128, activation='elu',name='FCN_2'))\n",
    "    model.add(Dense(4, activation= 'softmax',name='FCN_3'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute (Permute)            (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_1 (Conv2D)            (None, 32, 32, 64)        640       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 64)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 16, 128)       64        \n",
      "_________________________________________________________________\n",
      "Conv2D_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16, 16, 128)       64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8, 8, 256)         32        \n",
      "_________________________________________________________________\n",
      "Conv2D_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 8, 8, 256)         32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "FCN_1 (Dense)                (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "FCN_2 (Dense)                (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "FCN_3 (Dense)                (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 3,271,492\n",
      "Trainable params: 3,271,332\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32,32,1)\n",
    "learn_rate = 1e-5\n",
    "decay = 1e-03\n",
    "batch_size = 64\n",
    "epochs = 25\n",
    "drop = True\n",
    "dropRate = 0.3\n",
    "reg = 1e-2\n",
    "NNet = get_net(input_shape,drop,dropRate,reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute_1 (Permute)          (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_1 (Conv2D)            (None, 32, 32, 64)        640       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 32, 32, 64)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 16, 16, 128)       64        \n",
      "_________________________________________________________________\n",
      "Conv2D_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 16, 16, 128)       64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 8, 8, 256)         32        \n",
      "_________________________________________________________________\n",
      "Conv2D_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 8, 8, 256)         32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "FCN_1 (Dense)                (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "FCN_2 (Dense)                (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "FCN_3 (Dense)                (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 3,271,492\n",
      "Trainable params: 3,271,332\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 28/2/2021: Why get_net is used twice with same parameters?\n",
    "NNet=get_net(input_shape,drop,dropRate,reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import *\n",
    "import os\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "#Defining the optimizar parameters:\n",
    "AdamOpt = Adam(lr=learn_rate,decay=decay)\n",
    "\n",
    "#Compile the network: \n",
    "NNet.compile(optimizer=AdamOpt, metrics=['acc'], loss='categorical_crossentropy')\n",
    "\n",
    "#Saving checkpoints during training:\n",
    "Checkpath = os.getcwd()\n",
    "Checkp = ModelCheckpoint(Checkpath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, save_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6474 samples, validate on 1728 samples\n",
      "Epoch 1/25\n",
      "6474/6474 [==============================] - 130s 20ms/sample - loss: 8.0217 - acc: 0.4265 - val_loss: 7.8769 - val_acc: 0.2500\n",
      "Epoch 2/25\n",
      "6474/6474 [==============================] - 129s 20ms/sample - loss: 7.6170 - acc: 0.5270 - val_loss: 7.9627 - val_acc: 0.2500\n",
      "Epoch 3/25\n",
      "6474/6474 [==============================] - 128s 20ms/sample - loss: 7.4584 - acc: 0.5690 - val_loss: 8.0235 - val_acc: 0.2500\n",
      "Epoch 4/25\n",
      "6474/6474 [==============================] - 131s 20ms/sample - loss: 7.3373 - acc: 0.6033 - val_loss: 8.0465 - val_acc: 0.2500\n",
      "Epoch 5/25\n",
      "6474/6474 [==============================] - 139s 21ms/sample - loss: 7.2513 - acc: 0.6330 - val_loss: 7.9541 - val_acc: 0.2488\n",
      "Epoch 6/25\n",
      "6474/6474 [==============================] - 138s 21ms/sample - loss: 7.1775 - acc: 0.6486 - val_loss: 7.8177 - val_acc: 0.2795\n",
      "Epoch 7/25\n",
      "6474/6474 [==============================] - 130s 20ms/sample - loss: 7.0990 - acc: 0.6708 - val_loss: 7.6896 - val_acc: 0.3229\n",
      "Epoch 8/25\n",
      "6474/6474 [==============================] - 130s 20ms/sample - loss: 7.0373 - acc: 0.6923 - val_loss: 7.5904 - val_acc: 0.3576\n",
      "Epoch 9/25\n",
      "6474/6474 [==============================] - 132s 20ms/sample - loss: 6.9937 - acc: 0.6948 - val_loss: 7.5935 - val_acc: 0.3571\n",
      "Epoch 10/25\n",
      "6474/6474 [==============================] - 130s 20ms/sample - loss: 6.9261 - acc: 0.7207 - val_loss: 7.6052 - val_acc: 0.3536\n",
      "Epoch 11/25\n",
      "6474/6474 [==============================] - 129s 20ms/sample - loss: 6.8912 - acc: 0.7243 - val_loss: 7.5996 - val_acc: 0.3605\n",
      "Epoch 12/25\n",
      "6474/6474 [==============================] - 129s 20ms/sample - loss: 6.8575 - acc: 0.7345 - val_loss: 7.5557 - val_acc: 0.3721\n",
      "Epoch 13/25\n",
      "6474/6474 [==============================] - 131s 20ms/sample - loss: 6.8119 - acc: 0.7433 - val_loss: 7.5561 - val_acc: 0.3692\n",
      "Epoch 14/25\n",
      "6474/6474 [==============================] - 130s 20ms/sample - loss: 6.7736 - acc: 0.7546 - val_loss: 7.5791 - val_acc: 0.3582\n",
      "Epoch 15/25\n",
      "6474/6474 [==============================] - 130s 20ms/sample - loss: 6.7511 - acc: 0.7501 - val_loss: 7.5740 - val_acc: 0.3640\n",
      "Epoch 16/25\n",
      "6474/6474 [==============================] - 139s 21ms/sample - loss: 6.7144 - acc: 0.7569 - val_loss: 7.5063 - val_acc: 0.3796\n",
      "Epoch 17/25\n",
      "6474/6474 [==============================] - 141s 22ms/sample - loss: 6.6881 - acc: 0.7649 - val_loss: 7.5161 - val_acc: 0.3715\n",
      "Epoch 18/25\n",
      "6474/6474 [==============================] - 138s 21ms/sample - loss: 6.6396 - acc: 0.7739 - val_loss: 7.5296 - val_acc: 0.3715\n",
      "Epoch 19/25\n",
      "6474/6474 [==============================] - 155s 24ms/sample - loss: 6.6093 - acc: 0.7821 - val_loss: 7.5346 - val_acc: 0.3738\n",
      "Epoch 20/25\n",
      "6474/6474 [==============================] - 130s 20ms/sample - loss: 6.5757 - acc: 0.7864 - val_loss: 7.5016 - val_acc: 0.3825\n",
      "Epoch 21/25\n",
      "6474/6474 [==============================] - 131s 20ms/sample - loss: 6.5549 - acc: 0.7888 - val_loss: 7.5473 - val_acc: 0.3738\n",
      "Epoch 22/25\n",
      "6474/6474 [==============================] - 130s 20ms/sample - loss: 6.5241 - acc: 0.8014 - val_loss: 7.4853 - val_acc: 0.3808\n",
      "Epoch 23/25\n",
      "6474/6474 [==============================] - 130s 20ms/sample - loss: 6.4982 - acc: 0.8035 - val_loss: 7.4667 - val_acc: 0.3860\n",
      "Epoch 24/25\n",
      "6474/6474 [==============================] - 129s 20ms/sample - loss: 6.4819 - acc: 0.7995 - val_loss: 7.4731 - val_acc: 0.3848\n",
      "Epoch 25/25\n",
      "6474/6474 [==============================] - 129s 20ms/sample - loss: 6.4582 - acc: 0.8061 - val_loss: 7.4841 - val_acc: 0.3825\n"
     ]
    }
   ],
   "source": [
    "#Preforming the training by using fit \n",
    "# IMPORTANT NOTE: This will take a few minutes!\n",
    "h = NNet.fit(x=BaseX_train, y=BaseY_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0, validation_data = (BaseX_val, BaseY_val), shuffle=True)\n",
    "#NNet.save(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# NNet.load_weights('Weights_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at results/NNet.h5 \n"
     ]
    }
   ],
   "source": [
    "#new_a_model - with batch normalization:\n",
    "model_name = \"NNet.h5\"\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "NNet.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 1s 5ms/sample - loss: 8.0398 - acc: 0.2800\n",
      "test loss, test acc: [8.039812412261963, 0.28]\n"
     ]
    }
   ],
   "source": [
    "results = NNet.evaluate(X_test,Y_test)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">***Task 2:***</span> *Number of filters* \n",
    "\n",
    "Rebuild the function `get_net` to have as an input argument a list of number of filters in each layers, i.e. for the CNN defined above the input should have been `[64, 128, 128, 256, 256]`. Now train the model with the number of filters reduced by half. What were the results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "def get_net(input_shape,drop,dropRate,reg, filter_num1, filter_num2, filter_num3, filter_num4, filter_num5):\n",
    "    #Defining the network architecture:\n",
    "    model = Sequential()\n",
    "    model.add(Permute((1,2,3),input_shape = input_shape))\n",
    "    model.add(Conv2D(filters=filter_num1, kernel_size=(3,3), padding='same', activation='relu',name='Conv2D_1',kernel_regularizer=regularizers.l2(reg)))\n",
    "    if drop:\n",
    "        model.add(Dropout(rate=dropRate))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=filter_num2, kernel_size=(3,3), padding='same', activation='relu',name='Conv2D_2',kernel_regularizer=regularizers.l2(reg)))\n",
    "    if drop:    \n",
    "        model.add(Dropout(rate=dropRate))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Conv2D(filters=filter_num3, kernel_size=(3,3), padding='same', activation='relu',name='Conv2D_3',kernel_regularizer=regularizers.l2(reg)))\n",
    "    if drop:\n",
    "        model.add(Dropout(rate=dropRate))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=filter_num4, kernel_size=(3,3), padding='same', activation='relu',name='Conv2D_4',kernel_regularizer=regularizers.l2(reg)))\n",
    "    if drop:\n",
    "        model.add(Dropout(rate=dropRate))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Conv2D(filters=filter_num5, kernel_size=(3,3), padding='same', activation='relu',name='Conv2D_5',kernel_regularizer=regularizers.l2(reg)))\n",
    "    if drop:\n",
    "        model.add(Dropout(rate=dropRate))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    #Fully connected network tail:      \n",
    "    model.add(Dense(512, activation='elu',name='FCN_1')) \n",
    "    if drop:\n",
    "        model.add(Dropout(rate=dropRate))\n",
    "    model.add(Dense(128, activation='elu',name='FCN_2'))\n",
    "    model.add(Dense(4, activation= 'softmax',name='FCN_3'))\n",
    "    model.summary()\n",
    "    return model\n",
    "#----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute_1 (Permute)          (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_1 (Conv2D)            (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16, 16, 64)        64        \n",
      "_________________________________________________________________\n",
      "Conv2D_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 16, 16, 64)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "Conv2D_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 8, 8, 128)         32        \n",
      "_________________________________________________________________\n",
      "Conv2D_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8, 8, 128)         32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "FCN_1 (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "FCN_2 (Dense)                (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "FCN_3 (Dense)                (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 1,392,772\n",
      "Trainable params: 1,392,612\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter_n1 = 32\n",
    "filter_n2 = 64\n",
    "filter_n3 = 64\n",
    "filter_n4 = 128\n",
    "filter_n5 = 128\n",
    "# 28/02/2021: Change the input to a \"list\" instead of 5 int?\n",
    "NNet_half = get_net(input_shape,drop,dropRate,reg, filter_n1, filter_n2, filter_n3, filter_n4, filter_n5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6474 samples, validate on 1728 samples\n",
      "Epoch 1/25\n",
      "6474/6474 [==============================] - 51s 8ms/sample - loss: 5.0272 - acc: 0.3791 - val_loss: 4.7026 - val_acc: 0.2488\n",
      "Epoch 2/25\n",
      "6474/6474 [==============================] - 49s 8ms/sample - loss: 4.6795 - acc: 0.4651 - val_loss: 4.8885 - val_acc: 0.2390\n",
      "Epoch 3/25\n",
      "6474/6474 [==============================] - 49s 8ms/sample - loss: 4.5246 - acc: 0.4994 - val_loss: 5.0239 - val_acc: 0.2321\n",
      "Epoch 4/25\n",
      "6474/6474 [==============================] - 49s 8ms/sample - loss: 4.4227 - acc: 0.5207 - val_loss: 4.9750 - val_acc: 0.2593\n",
      "Epoch 5/25\n",
      "6474/6474 [==============================] - 49s 8ms/sample - loss: 4.3526 - acc: 0.5440 - val_loss: 4.8142 - val_acc: 0.2998\n",
      "Epoch 6/25\n",
      "6474/6474 [==============================] - 49s 8ms/sample - loss: 4.2715 - acc: 0.5664 - val_loss: 4.6575 - val_acc: 0.3848\n",
      "Epoch 7/25\n",
      "6474/6474 [==============================] - 49s 8ms/sample - loss: 4.2317 - acc: 0.5812 - val_loss: 4.5493 - val_acc: 0.4323\n",
      "Epoch 8/25\n",
      "6474/6474 [==============================] - 59s 9ms/sample - loss: 4.1845 - acc: 0.5930 - val_loss: 4.5000 - val_acc: 0.4572\n",
      "Epoch 9/25\n",
      "6474/6474 [==============================] - 49s 8ms/sample - loss: 4.1364 - acc: 0.6131 - val_loss: 4.4666 - val_acc: 0.4745\n",
      "Epoch 10/25\n",
      "6474/6474 [==============================] - 48s 7ms/sample - loss: 4.1158 - acc: 0.6172 - val_loss: 4.4704 - val_acc: 0.4711\n",
      "Epoch 11/25\n",
      "6474/6474 [==============================] - 48s 7ms/sample - loss: 4.0872 - acc: 0.6288 - val_loss: 4.4515 - val_acc: 0.4861\n",
      "Epoch 12/25\n",
      "6474/6474 [==============================] - 50s 8ms/sample - loss: 4.0698 - acc: 0.6291 - val_loss: 4.4437 - val_acc: 0.4890\n",
      "Epoch 13/25\n",
      "6474/6474 [==============================] - 48s 7ms/sample - loss: 4.0352 - acc: 0.6452 - val_loss: 4.4363 - val_acc: 0.4919\n",
      "Epoch 14/25\n",
      "6474/6474 [==============================] - 48s 7ms/sample - loss: 4.0116 - acc: 0.6489 - val_loss: 4.4404 - val_acc: 0.4861\n",
      "Epoch 15/25\n",
      "6474/6474 [==============================] - 48s 7ms/sample - loss: 3.9799 - acc: 0.6677 - val_loss: 4.4367 - val_acc: 0.4907\n",
      "Epoch 16/25\n",
      "6474/6474 [==============================] - 48s 7ms/sample - loss: 3.9644 - acc: 0.6691 - val_loss: 4.4320 - val_acc: 0.4867\n",
      "Epoch 17/25\n",
      "6474/6474 [==============================] - 48s 7ms/sample - loss: 3.9560 - acc: 0.6634 - val_loss: 4.4315 - val_acc: 0.4861\n",
      "Epoch 18/25\n",
      "6474/6474 [==============================] - 48s 7ms/sample - loss: 3.9288 - acc: 0.6708 - val_loss: 4.4358 - val_acc: 0.4832\n",
      "Epoch 19/25\n",
      "6474/6474 [==============================] - 49s 8ms/sample - loss: 3.9257 - acc: 0.6866 - val_loss: 4.4206 - val_acc: 0.4861\n",
      "Epoch 20/25\n",
      "6474/6474 [==============================] - 48s 7ms/sample - loss: 3.9106 - acc: 0.6855 - val_loss: 4.4091 - val_acc: 0.4884\n",
      "Epoch 21/25\n",
      "6474/6474 [==============================] - 48s 7ms/sample - loss: 3.8818 - acc: 0.6986 - val_loss: 4.4056 - val_acc: 0.4873\n",
      "Epoch 22/25\n",
      "6474/6474 [==============================] - 48s 7ms/sample - loss: 3.8691 - acc: 0.6946 - val_loss: 4.4046 - val_acc: 0.4844\n",
      "Epoch 23/25\n",
      "6474/6474 [==============================] - 48s 7ms/sample - loss: 3.8586 - acc: 0.7006 - val_loss: 4.3965 - val_acc: 0.4838\n",
      "Epoch 24/25\n",
      "6474/6474 [==============================] - 48s 7ms/sample - loss: 3.8532 - acc: 0.6945 - val_loss: 4.3937 - val_acc: 0.4838\n",
      "Epoch 25/25\n",
      "6474/6474 [==============================] - 49s 8ms/sample - loss: 3.8248 - acc: 0.7091 - val_loss: 4.4026 - val_acc: 0.4821\n"
     ]
    }
   ],
   "source": [
    "#Defining the optimizar parameters:\n",
    "AdamOpt = Adam(lr=learn_rate,decay=decay)\n",
    "\n",
    "#Compile the network: \n",
    "NNet_half.compile(optimizer=AdamOpt, metrics=['acc'], loss='categorical_crossentropy')\n",
    "\n",
    "#Saving checkpoints during training:\n",
    "Checkpath = os.getcwd()\n",
    "Checkp = ModelCheckpoint(Checkpath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, save_freq=1)\n",
    "\n",
    "#Preforming the training by using fit \n",
    "# IMPORTANT NOTE: This will take a few minutes!\n",
    "h = NNet_half.fit(x=BaseX_train, y=BaseY_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0, validation_data = (BaseX_val, BaseY_val), shuffle=True)\n",
    "#NNet_half.save(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at results/NNet_half.h5 \n"
     ]
    }
   ],
   "source": [
    "#new_a_model - with batch normalization:\n",
    "model_name = \"NNet_half.h5\"\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "NNet_half.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 1s 4ms/sample - loss: 4.8789 - acc: 0.3543\n",
      "test loss, test acc: [4.878927459716797, 0.35428572]\n"
     ]
    }
   ],
   "source": [
    "results = NNet_half.evaluate(X_test,Y_test)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all folks! See you :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
